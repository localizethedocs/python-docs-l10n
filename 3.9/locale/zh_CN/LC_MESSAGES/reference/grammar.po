# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2001-2025, Python Software Foundation
# This file is distributed under the same license as the Python package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python 3.9\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-10 15:08+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../reference/grammar.rst:2
msgid "Full Grammar specification"
msgstr ""

#: ../../../reference/grammar.rst:4
msgid ""
"This is the full Python grammar, derived directly from the grammar used to "
"generate the CPython parser (see :source:`Grammar/python.gram`). The version "
"here omits details related to code generation and error recovery."
msgstr ""

#: ../../../reference/grammar.rst:9
msgid ""
"The notation is a mixture of `EBNF <https://en.wikipedia.org/wiki/"
"Extended_Backus%E2%80%93Naur_form>`_ and `PEG <https://en.wikipedia.org/wiki/"
"Parsing_expression_grammar>`_. In particular, ``&`` followed by a symbol, "
"token or parenthesized group indicates a positive lookahead (i.e., is "
"required to match but not consumed), while ``!`` indicates a negative "
"lookahead (i.e., is required _not_ to match).  We use the ``|`` separator to "
"mean PEG's \"ordered choice\" (written as ``/`` in traditional PEG grammars)."
msgstr ""

#: ../../../reference/grammar.rst:18
msgid ""
"# PEG grammar for Python\n"
"\n"
"@trailer '''\n"
"void *\n"
"_PyPegen_parse(Parser *p)\n"
"{\n"
"    // Initialize keywords\n"
"    p->keywords = reserved_keywords;\n"
"    p->n_keyword_lists = n_keyword_lists;\n"
"\n"
"    // Run parser\n"
"    void *result = NULL;\n"
"    if (p->start_rule == Py_file_input) {\n"
"        result = file_rule(p);\n"
"    } else if (p->start_rule == Py_single_input) {\n"
"        result = interactive_rule(p);\n"
"    } else if (p->start_rule == Py_eval_input) {\n"
"        result = eval_rule(p);\n"
"    } else if (p->start_rule == Py_func_type_input) {\n"
"        result = func_type_rule(p);\n"
"    } else if (p->start_rule == Py_fstring_input) {\n"
"        result = fstring_rule(p);\n"
"    }\n"
"\n"
"    return result;\n"
"}\n"
"\n"
"// The end\n"
"'''\n"
"file[mod_ty]: a=[statements] ENDMARKER { _PyPegen_make_module(p, a) }\n"
"interactive[mod_ty]: a=statement_newline { Interactive(a, p->arena) }\n"
"eval[mod_ty]: a=expressions NEWLINE* ENDMARKER { Expression(a, p->arena) }\n"
"func_type[mod_ty]: '(' a=[type_expressions] ')' '->' b=expression NEWLINE* "
"ENDMARKER { FunctionType(a, b, p->arena) }\n"
"fstring[expr_ty]: star_expressions\n"
"\n"
"# type_expressions allow */** but ignore them\n"
"type_expressions[asdl_seq*]:\n"
"    | a=','.expression+ ',' '*' b=expression ',' '**' c=expression {\n"
"        _PyPegen_seq_append_to_end(p, CHECK(_PyPegen_seq_append_to_end(p, a, "
"b)), c) }\n"
"    | a=','.expression+ ',' '*' b=expression { _PyPegen_seq_append_to_end(p, "
"a, b) }\n"
"    | a=','.expression+ ',' '**' b=expression "
"{ _PyPegen_seq_append_to_end(p, a, b) }\n"
"    | '*' a=expression ',' '**' b=expression {\n"
"        _PyPegen_seq_append_to_end(p, CHECK(_PyPegen_singleton_seq(p, a)), "
"b) }\n"
"    | '*' a=expression { _PyPegen_singleton_seq(p, a) }\n"
"    | '**' a=expression { _PyPegen_singleton_seq(p, a) }\n"
"    | ','.expression+\n"
"\n"
"statements[asdl_seq*]: a=statement+ { _PyPegen_seq_flatten(p, a) }\n"
"statement[asdl_seq*]: a=compound_stmt { _PyPegen_singleton_seq(p, a) } | "
"simple_stmt\n"
"statement_newline[asdl_seq*]:\n"
"    | a=compound_stmt NEWLINE { _PyPegen_singleton_seq(p, a) }\n"
"    | simple_stmt\n"
"    | NEWLINE { _PyPegen_singleton_seq(p, CHECK(_Py_Pass(EXTRA))) }\n"
"    | ENDMARKER { _PyPegen_interactive_exit(p) }\n"
"simple_stmt[asdl_seq*]:\n"
"    | a=small_stmt !';' NEWLINE { _PyPegen_singleton_seq(p, a) } # Not "
"needed, there for speedup\n"
"    | a=';'.small_stmt+ [';'] NEWLINE { a }\n"
"# NOTE: assignment MUST precede expression, else parsing a simple "
"assignment\n"
"# will throw a SyntaxError.\n"
"small_stmt[stmt_ty] (memo):\n"
"    | assignment\n"
"    | e=star_expressions { _Py_Expr(e, EXTRA) }\n"
"    | &'return' return_stmt\n"
"    | &('import' | 'from') import_stmt\n"
"    | &'raise' raise_stmt\n"
"    | 'pass' { _Py_Pass(EXTRA) }\n"
"    | &'del' del_stmt\n"
"    | &'yield' yield_stmt\n"
"    | &'assert' assert_stmt\n"
"    | 'break' { _Py_Break(EXTRA) }\n"
"    | 'continue' { _Py_Continue(EXTRA) }\n"
"    | &'global' global_stmt\n"
"    | &'nonlocal' nonlocal_stmt\n"
"compound_stmt[stmt_ty]:\n"
"    | &('def' | '@' | ASYNC) function_def\n"
"    | &'if' if_stmt\n"
"    | &('class' | '@') class_def\n"
"    | &('with' | ASYNC) with_stmt\n"
"    | &('for' | ASYNC) for_stmt\n"
"    | &'try' try_stmt\n"
"    | &'while' while_stmt\n"
"\n"
"# NOTE: annotated_rhs may start with 'yield'; yield_expr must start with "
"'yield'\n"
"assignment[stmt_ty]:\n"
"    | a=NAME ':' b=expression c=['=' d=annotated_rhs { d }] {\n"
"        CHECK_VERSION(\n"
"            6,\n"
"            \"Variable annotation syntax is\",\n"
"            _Py_AnnAssign(CHECK(_PyPegen_set_expr_context(p, a, Store)), b, "
"c, 1, EXTRA)\n"
"        ) }\n"
"    | a=('(' b=single_target ')' { b }\n"
"         | single_subscript_attribute_target) ':' b=expression c=['=' "
"d=annotated_rhs { d }] {\n"
"        CHECK_VERSION(6, \"Variable annotations syntax is\", "
"_Py_AnnAssign(a, b, c, 0, EXTRA)) }\n"
"    | a=(z=star_targets '=' { z })+ b=(yield_expr | star_expressions) !'=' "
"tc=[TYPE_COMMENT] {\n"
"         _Py_Assign(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }\n"
"    | a=single_target b=augassign ~ c=(yield_expr | star_expressions) {\n"
"         _Py_AugAssign(a, b->kind, c, EXTRA) }\n"
"    | invalid_assignment\n"
"\n"
"augassign[AugOperator*]:\n"
"    | '+=' { _PyPegen_augoperator(p, Add) }\n"
"    | '-=' { _PyPegen_augoperator(p, Sub) }\n"
"    | '*=' { _PyPegen_augoperator(p, Mult) }\n"
"    | '@=' { CHECK_VERSION(5, \"The '@' operator is\", "
"_PyPegen_augoperator(p, MatMult)) }\n"
"    | '/=' { _PyPegen_augoperator(p, Div) }\n"
"    | '%=' { _PyPegen_augoperator(p, Mod) }\n"
"    | '&=' { _PyPegen_augoperator(p, BitAnd) }\n"
"    | '|=' { _PyPegen_augoperator(p, BitOr) }\n"
"    | '^=' { _PyPegen_augoperator(p, BitXor) }\n"
"    | '<<=' { _PyPegen_augoperator(p, LShift) }\n"
"    | '>>=' { _PyPegen_augoperator(p, RShift) }\n"
"    | '**=' { _PyPegen_augoperator(p, Pow) }\n"
"    | '//=' { _PyPegen_augoperator(p, FloorDiv) }\n"
"\n"
"global_stmt[stmt_ty]: 'global' a=','.NAME+ {\n"
"    _Py_Global(CHECK(_PyPegen_map_names_to_ids(p, a)), EXTRA) }\n"
"nonlocal_stmt[stmt_ty]: 'nonlocal' a=','.NAME+ {\n"
"    _Py_Nonlocal(CHECK(_PyPegen_map_names_to_ids(p, a)), EXTRA) }\n"
"\n"
"yield_stmt[stmt_ty]: y=yield_expr { _Py_Expr(y, EXTRA) }\n"
"\n"
"assert_stmt[stmt_ty]: 'assert' a=expression b=[',' z=expression { z }] "
"{ _Py_Assert(a, b, EXTRA) }\n"
"\n"
"del_stmt[stmt_ty]:\n"
"    | 'del' a=del_targets &(';' | NEWLINE) { _Py_Delete(a, EXTRA) }\n"
"    | invalid_del_stmt\n"
"\n"
"import_stmt[stmt_ty]: import_name | import_from\n"
"import_name[stmt_ty]: 'import' a=dotted_as_names { _Py_Import(a, EXTRA) }\n"
"# note below: the ('.' | '...') is necessary because '...' is tokenized as "
"ELLIPSIS\n"
"import_from[stmt_ty]:\n"
"    | 'from' a=('.' | '...')* b=dotted_name 'import' c=import_from_targets "
"{\n"
"        _Py_ImportFrom(b->v.Name.id, c, _PyPegen_seq_count_dots(a), "
"EXTRA) }\n"
"    | 'from' a=('.' | '...')+ 'import' b=import_from_targets {\n"
"        _Py_ImportFrom(NULL, b, _PyPegen_seq_count_dots(a), EXTRA) }\n"
"import_from_targets[asdl_seq*]:\n"
"    | '(' a=import_from_as_names [','] ')' { a }\n"
"    | import_from_as_names !','\n"
"    | '*' { _PyPegen_singleton_seq(p, CHECK(_PyPegen_alias_for_star(p))) }\n"
"    | invalid_import_from_targets\n"
"import_from_as_names[asdl_seq*]:\n"
"    | a=','.import_from_as_name+ { a }\n"
"import_from_as_name[alias_ty]:\n"
"    | a=NAME b=['as' z=NAME { z }] { _Py_alias(a->v.Name.id,\n"
"                                               (b) ? ((expr_ty) b)->v.Name."
"id : NULL,\n"
"                                               p->arena) }\n"
"dotted_as_names[asdl_seq*]:\n"
"    | a=','.dotted_as_name+ { a }\n"
"dotted_as_name[alias_ty]:\n"
"    | a=dotted_name b=['as' z=NAME { z }] { _Py_alias(a->v.Name.id,\n"
"                                                      (b) ? ((expr_ty) b)->v."
"Name.id : NULL,\n"
"                                                      p->arena) }\n"
"dotted_name[expr_ty]:\n"
"    | a=dotted_name '.' b=NAME { _PyPegen_join_names_with_dot(p, a, b) }\n"
"    | NAME\n"
"\n"
"if_stmt[stmt_ty]:\n"
"    | 'if' a=named_expression ':' b=block c=elif_stmt { _Py_If(a, b, "
"CHECK(_PyPegen_singleton_seq(p, c)), EXTRA) }\n"
"    | 'if' a=named_expression ':' b=block c=[else_block] { _Py_If(a, b, c, "
"EXTRA) }\n"
"elif_stmt[stmt_ty]:\n"
"    | 'elif' a=named_expression ':' b=block c=elif_stmt { _Py_If(a, b, "
"CHECK(_PyPegen_singleton_seq(p, c)), EXTRA) }\n"
"    | 'elif' a=named_expression ':' b=block c=[else_block] { _Py_If(a, b, c, "
"EXTRA) }\n"
"else_block[asdl_seq*]: 'else' ':' b=block { b }\n"
"\n"
"while_stmt[stmt_ty]:\n"
"    | 'while' a=named_expression ':' b=block c=[else_block] { _Py_While(a, "
"b, c, EXTRA) }\n"
"\n"
"for_stmt[stmt_ty]:\n"
"    | 'for' t=star_targets 'in' ~ ex=star_expressions ':' tc=[TYPE_COMMENT] "
"b=block el=[else_block] {\n"
"        _Py_For(t, ex, b, el, NEW_TYPE_COMMENT(p, tc), EXTRA) }\n"
"    | ASYNC 'for' t=star_targets 'in' ~ ex=star_expressions ':' "
"tc=[TYPE_COMMENT] b=block el=[else_block] {\n"
"        CHECK_VERSION(5, \"Async for loops are\", _Py_AsyncFor(t, ex, b, el, "
"NEW_TYPE_COMMENT(p, tc), EXTRA)) }\n"
"    | invalid_for_target\n"
"\n"
"with_stmt[stmt_ty]:\n"
"    | 'with' '(' a=','.with_item+ ','? ')' ':' b=block {\n"
"        _Py_With(a, b, NULL, EXTRA) }\n"
"    | 'with' a=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {\n"
"        _Py_With(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }\n"
"    | ASYNC 'with' '(' a=','.with_item+ ','? ')' ':' b=block {\n"
"       CHECK_VERSION(5, \"Async with statements are\", _Py_AsyncWith(a, b, "
"NULL, EXTRA)) }\n"
"    | ASYNC 'with' a=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {\n"
"       CHECK_VERSION(5, \"Async with statements are\", _Py_AsyncWith(a, b, "
"NEW_TYPE_COMMENT(p, tc), EXTRA)) }\n"
"with_item[withitem_ty]:\n"
"    | e=expression 'as' t=star_target &(',' | ')' | ':') { _Py_withitem(e, "
"t, p->arena) }\n"
"    | invalid_with_item\n"
"    | e=expression { _Py_withitem(e, NULL, p->arena) }\n"
"\n"
"try_stmt[stmt_ty]:\n"
"    | 'try' ':' b=block f=finally_block { _Py_Try(b, NULL, NULL, f, "
"EXTRA) }\n"
"    | 'try' ':' b=block ex=except_block+ el=[else_block] f=[finally_block] "
"{ _Py_Try(b, ex, el, f, EXTRA) }\n"
"except_block[excepthandler_ty]:\n"
"    | 'except' e=expression t=['as' z=NAME { z }] ':' b=block {\n"
"        _Py_ExceptHandler(e, (t) ? ((expr_ty) t)->v.Name.id : NULL, b, "
"EXTRA) }\n"
"    | 'except' ':' b=block { _Py_ExceptHandler(NULL, NULL, b, EXTRA) }\n"
"finally_block[asdl_seq*]: 'finally' ':' a=block { a }\n"
"\n"
"return_stmt[stmt_ty]:\n"
"    | 'return' a=[star_expressions] { _Py_Return(a, EXTRA) }\n"
"\n"
"raise_stmt[stmt_ty]:\n"
"    | 'raise' a=expression b=['from' z=expression { z }] { _Py_Raise(a, b, "
"EXTRA) }\n"
"    | 'raise' { _Py_Raise(NULL, NULL, EXTRA) }\n"
"\n"
"function_def[stmt_ty]:\n"
"    | d=decorators f=function_def_raw { _PyPegen_function_def_decorators(p, "
"d, f) }\n"
"    | function_def_raw\n"
"\n"
"function_def_raw[stmt_ty]:\n"
"    | 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] ':' "
"tc=[func_type_comment] b=block {\n"
"        _Py_FunctionDef(n->v.Name.id,\n"
"                        (params) ? params : "
"CHECK(_PyPegen_empty_arguments(p)),\n"
"                        b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA) }\n"
"    | ASYNC 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] "
"':' tc=[func_type_comment] b=block {\n"
"        CHECK_VERSION(\n"
"            5,\n"
"            \"Async functions are\",\n"
"            _Py_AsyncFunctionDef(n->v.Name.id,\n"
"                            (params) ? params : "
"CHECK(_PyPegen_empty_arguments(p)),\n"
"                            b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA)\n"
"        ) }\n"
"func_type_comment[Token*]:\n"
"    | NEWLINE t=TYPE_COMMENT &(NEWLINE INDENT) { t }  # Must be followed by "
"indented block\n"
"    | invalid_double_type_comments\n"
"    | TYPE_COMMENT\n"
"\n"
"params[arguments_ty]:\n"
"    | invalid_parameters\n"
"    | parameters\n"
"\n"
"parameters[arguments_ty]:\n"
"    | a=slash_no_default b=param_no_default* c=param_with_default* "
"d=[star_etc] {\n"
"        _PyPegen_make_arguments(p, a, NULL, b, c, d) }\n"
"    | a=slash_with_default b=param_with_default* c=[star_etc] {\n"
"        _PyPegen_make_arguments(p, NULL, a, NULL, b, c) }\n"
"    | a=param_no_default+ b=param_with_default* c=[star_etc] {\n"
"        _PyPegen_make_arguments(p, NULL, NULL, a, b, c) }\n"
"    | a=param_with_default+ b=[star_etc] { _PyPegen_make_arguments(p, NULL, "
"NULL, NULL, a, b)}\n"
"    | a=star_etc { _PyPegen_make_arguments(p, NULL, NULL, NULL, NULL, a) }\n"
"\n"
"# Some duplication here because we can't write (',' | &')'),\n"
"# which is because we don't support empty alternatives (yet).\n"
"#\n"
"slash_no_default[asdl_seq*]:\n"
"    | a=param_no_default+ '/' ',' { a }\n"
"    | a=param_no_default+ '/' &')' { a }\n"
"slash_with_default[SlashWithDefault*]:\n"
"    | a=param_no_default* b=param_with_default+ '/' "
"',' { _PyPegen_slash_with_default(p, a, b) }\n"
"    | a=param_no_default* b=param_with_default+ '/' "
"&')' { _PyPegen_slash_with_default(p, a, b) }\n"
"\n"
"star_etc[StarEtc*]:\n"
"    | '*' a=param_no_default b=param_maybe_default* c=[kwds] {\n"
"        _PyPegen_star_etc(p, a, b, c) }\n"
"    | '*' ',' b=param_maybe_default+ c=[kwds] {\n"
"        _PyPegen_star_etc(p, NULL, b, c) }\n"
"    | a=kwds { _PyPegen_star_etc(p, NULL, NULL, a) }\n"
"    | invalid_star_etc\n"
"\n"
"kwds[arg_ty]: '**' a=param_no_default { a }\n"
"\n"
"# One parameter.  This *includes* a following comma and type comment.\n"
"#\n"
"# There are three styles:\n"
"# - No default\n"
"# - With default\n"
"# - Maybe with default\n"
"#\n"
"# There are two alternative forms of each, to deal with type comments:\n"
"# - Ends in a comma followed by an optional type comment\n"
"# - No comma, optional type comment, must be followed by close paren\n"
"# The latter form is for a final parameter without trailing comma.\n"
"#\n"
"param_no_default[arg_ty]:\n"
"    | a=param ',' tc=TYPE_COMMENT? { _PyPegen_add_type_comment_to_arg(p, a, "
"tc) }\n"
"    | a=param tc=TYPE_COMMENT? &')' { _PyPegen_add_type_comment_to_arg(p, a, "
"tc) }\n"
"param_with_default[NameDefaultPair*]:\n"
"    | a=param c=default ',' tc=TYPE_COMMENT? { _PyPegen_name_default_pair(p, "
"a, c, tc) }\n"
"    | a=param c=default tc=TYPE_COMMENT? "
"&')' { _PyPegen_name_default_pair(p, a, c, tc) }\n"
"param_maybe_default[NameDefaultPair*]:\n"
"    | a=param c=default? ',' tc=TYPE_COMMENT? "
"{ _PyPegen_name_default_pair(p, a, c, tc) }\n"
"    | a=param c=default? tc=TYPE_COMMENT? "
"&')' { _PyPegen_name_default_pair(p, a, c, tc) }\n"
"param[arg_ty]: a=NAME b=annotation? { _Py_arg(a->v.Name.id, b, NULL, "
"EXTRA) }\n"
"\n"
"annotation[expr_ty]: ':' a=expression { a }\n"
"default[expr_ty]: '=' a=expression { a }\n"
"\n"
"decorators[asdl_seq*]: a=('@' f=named_expression NEWLINE { f })+ { a }\n"
"\n"
"class_def[stmt_ty]:\n"
"    | a=decorators b=class_def_raw { _PyPegen_class_def_decorators(p, a, "
"b) }\n"
"    | class_def_raw\n"
"class_def_raw[stmt_ty]:\n"
"    | 'class' a=NAME b=['(' z=[arguments] ')' { z }] ':' c=block {\n"
"        _Py_ClassDef(a->v.Name.id,\n"
"                     (b) ? ((expr_ty) b)->v.Call.args : NULL,\n"
"                     (b) ? ((expr_ty) b)->v.Call.keywords : NULL,\n"
"                     c, NULL, EXTRA) }\n"
"\n"
"block[asdl_seq*] (memo):\n"
"    | NEWLINE INDENT a=statements DEDENT { a }\n"
"    | simple_stmt\n"
"    | invalid_block\n"
"\n"
"star_expressions[expr_ty]:\n"
"    | a=star_expression b=(',' c=star_expression { c })+ [','] {\n"
"        _Py_Tuple(CHECK(_PyPegen_seq_insert_in_front(p, a, b)), Load, "
"EXTRA) }\n"
"    | a=star_expression ',' { _Py_Tuple(CHECK(_PyPegen_singleton_seq(p, a)), "
"Load, EXTRA) }\n"
"    | star_expression\n"
"star_expression[expr_ty] (memo):\n"
"    | '*' a=bitwise_or { _Py_Starred(a, Load, EXTRA) }\n"
"    | expression\n"
"\n"
"star_named_expressions[asdl_seq*]: a=','.star_named_expression+ [','] { a }\n"
"star_named_expression[expr_ty]:\n"
"    | '*' a=bitwise_or { _Py_Starred(a, Load, EXTRA) }\n"
"    | named_expression\n"
"named_expression[expr_ty]:\n"
"    | a=NAME ':=' ~ b=expression "
"{ _Py_NamedExpr(CHECK(_PyPegen_set_expr_context(p, a, Store)), b, EXTRA) }\n"
"    | expression !':='\n"
"    | invalid_named_expression\n"
"\n"
"annotated_rhs[expr_ty]: yield_expr | star_expressions\n"
"\n"
"expressions[expr_ty]:\n"
"    | a=expression b=(',' c=expression { c })+ [','] {\n"
"        _Py_Tuple(CHECK(_PyPegen_seq_insert_in_front(p, a, b)), Load, "
"EXTRA) }\n"
"    | a=expression ',' { _Py_Tuple(CHECK(_PyPegen_singleton_seq(p, a)), "
"Load, EXTRA) }\n"
"    | expression\n"
"expression[expr_ty] (memo):\n"
"    | a=disjunction 'if' b=disjunction 'else' c=expression { _Py_IfExp(b, a, "
"c, EXTRA) }\n"
"    | disjunction\n"
"    | lambdef\n"
"\n"
"lambdef[expr_ty]:\n"
"    | 'lambda' a=[lambda_params] ':' b=expression { _Py_Lambda((a) ? a : "
"CHECK(_PyPegen_empty_arguments(p)), b, EXTRA) }\n"
"\n"
"lambda_params[arguments_ty]:\n"
"    | invalid_lambda_parameters\n"
"    | lambda_parameters\n"
"\n"
"# lambda_parameters etc. duplicates parameters but without annotations\n"
"# or type comments, and if there's no comma after a parameter, we expect\n"
"# a colon, not a close parenthesis.  (For more, see parameters above.)\n"
"#\n"
"lambda_parameters[arguments_ty]:\n"
"    | a=lambda_slash_no_default b=lambda_param_no_default* "
"c=lambda_param_with_default* d=[lambda_star_etc] {\n"
"        _PyPegen_make_arguments(p, a, NULL, b, c, d) }\n"
"    | a=lambda_slash_with_default b=lambda_param_with_default* "
"c=[lambda_star_etc] {\n"
"        _PyPegen_make_arguments(p, NULL, a, NULL, b, c) }\n"
"    | a=lambda_param_no_default+ b=lambda_param_with_default* "
"c=[lambda_star_etc] {\n"
"        _PyPegen_make_arguments(p, NULL, NULL, a, b, c) }\n"
"    | a=lambda_param_with_default+ b=[lambda_star_etc] "
"{ _PyPegen_make_arguments(p, NULL, NULL, NULL, a, b)}\n"
"    | a=lambda_star_etc { _PyPegen_make_arguments(p, NULL, NULL, NULL, NULL, "
"a) }\n"
"\n"
"lambda_slash_no_default[asdl_seq*]:\n"
"    | a=lambda_param_no_default+ '/' ',' { a }\n"
"    | a=lambda_param_no_default+ '/' &':' { a }\n"
"lambda_slash_with_default[SlashWithDefault*]:\n"
"    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' "
"',' { _PyPegen_slash_with_default(p, a, b) }\n"
"    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' "
"&':' { _PyPegen_slash_with_default(p, a, b) }\n"
"\n"
"lambda_star_etc[StarEtc*]:\n"
"    | '*' a=lambda_param_no_default b=lambda_param_maybe_default* "
"c=[lambda_kwds] {\n"
"        _PyPegen_star_etc(p, a, b, c) }\n"
"    | '*' ',' b=lambda_param_maybe_default+ c=[lambda_kwds] {\n"
"        _PyPegen_star_etc(p, NULL, b, c) }\n"
"    | a=lambda_kwds { _PyPegen_star_etc(p, NULL, NULL, a) }\n"
"    | invalid_lambda_star_etc\n"
"\n"
"lambda_kwds[arg_ty]: '**' a=lambda_param_no_default { a }\n"
"\n"
"lambda_param_no_default[arg_ty]:\n"
"    | a=lambda_param ',' { a }\n"
"    | a=lambda_param &':' { a }\n"
"lambda_param_with_default[NameDefaultPair*]:\n"
"    | a=lambda_param c=default ',' { _PyPegen_name_default_pair(p, a, c, "
"NULL) }\n"
"    | a=lambda_param c=default &':' { _PyPegen_name_default_pair(p, a, c, "
"NULL) }\n"
"lambda_param_maybe_default[NameDefaultPair*]:\n"
"    | a=lambda_param c=default? ',' { _PyPegen_name_default_pair(p, a, c, "
"NULL) }\n"
"    | a=lambda_param c=default? &':' { _PyPegen_name_default_pair(p, a, c, "
"NULL) }\n"
"lambda_param[arg_ty]: a=NAME { _Py_arg(a->v.Name.id, NULL, NULL, EXTRA) }\n"
"\n"
"disjunction[expr_ty] (memo):\n"
"    | a=conjunction b=('or' c=conjunction { c })+ { _Py_BoolOp(\n"
"        Or,\n"
"        CHECK(_PyPegen_seq_insert_in_front(p, a, b)),\n"
"        EXTRA) }\n"
"    | conjunction\n"
"conjunction[expr_ty] (memo):\n"
"    | a=inversion b=('and' c=inversion { c })+ { _Py_BoolOp(\n"
"        And,\n"
"        CHECK(_PyPegen_seq_insert_in_front(p, a, b)),\n"
"        EXTRA) }\n"
"    | inversion\n"
"inversion[expr_ty] (memo):\n"
"    | 'not' a=inversion { _Py_UnaryOp(Not, a, EXTRA) }\n"
"    | comparison\n"
"comparison[expr_ty]:\n"
"    | a=bitwise_or b=compare_op_bitwise_or_pair+ {\n"
"        _Py_Compare(a, CHECK(_PyPegen_get_cmpops(p, b)), "
"CHECK(_PyPegen_get_exprs(p, b)), EXTRA) }\n"
"    | bitwise_or\n"
"compare_op_bitwise_or_pair[CmpopExprPair*]:\n"
"    | eq_bitwise_or\n"
"    | noteq_bitwise_or\n"
"    | lte_bitwise_or\n"
"    | lt_bitwise_or\n"
"    | gte_bitwise_or\n"
"    | gt_bitwise_or\n"
"    | notin_bitwise_or\n"
"    | in_bitwise_or\n"
"    | isnot_bitwise_or\n"
"    | is_bitwise_or\n"
"eq_bitwise_or[CmpopExprPair*]: '==' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, Eq, a) }\n"
"noteq_bitwise_or[CmpopExprPair*]:\n"
"    | (tok='!=' { _PyPegen_check_barry_as_flufl(p, tok) ? NULL : tok}) "
"a=bitwise_or {_PyPegen_cmpop_expr_pair(p, NotEq, a) }\n"
"lte_bitwise_or[CmpopExprPair*]: '<=' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, LtE, a) }\n"
"lt_bitwise_or[CmpopExprPair*]: '<' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, Lt, a) }\n"
"gte_bitwise_or[CmpopExprPair*]: '>=' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, GtE, a) }\n"
"gt_bitwise_or[CmpopExprPair*]: '>' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, Gt, a) }\n"
"notin_bitwise_or[CmpopExprPair*]: 'not' 'in' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, NotIn, a) }\n"
"in_bitwise_or[CmpopExprPair*]: 'in' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, In, a) }\n"
"isnot_bitwise_or[CmpopExprPair*]: 'is' 'not' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, IsNot, a) }\n"
"is_bitwise_or[CmpopExprPair*]: 'is' a=bitwise_or "
"{ _PyPegen_cmpop_expr_pair(p, Is, a) }\n"
"\n"
"bitwise_or[expr_ty]:\n"
"    | a=bitwise_or '|' b=bitwise_xor { _Py_BinOp(a, BitOr, b, EXTRA) }\n"
"    | bitwise_xor\n"
"bitwise_xor[expr_ty]:\n"
"    | a=bitwise_xor '^' b=bitwise_and { _Py_BinOp(a, BitXor, b, EXTRA) }\n"
"    | bitwise_and\n"
"bitwise_and[expr_ty]:\n"
"    | a=bitwise_and '&' b=shift_expr { _Py_BinOp(a, BitAnd, b, EXTRA) }\n"
"    | shift_expr\n"
"shift_expr[expr_ty]:\n"
"    | a=shift_expr '<<' b=sum { _Py_BinOp(a, LShift, b, EXTRA) }\n"
"    | a=shift_expr '>>' b=sum { _Py_BinOp(a, RShift, b, EXTRA) }\n"
"    | sum\n"
"\n"
"sum[expr_ty]:\n"
"    | a=sum '+' b=term { _Py_BinOp(a, Add, b, EXTRA) }\n"
"    | a=sum '-' b=term { _Py_BinOp(a, Sub, b, EXTRA) }\n"
"    | term\n"
"term[expr_ty]:\n"
"    | a=term '*' b=factor { _Py_BinOp(a, Mult, b, EXTRA) }\n"
"    | a=term '/' b=factor { _Py_BinOp(a, Div, b, EXTRA) }\n"
"    | a=term '//' b=factor { _Py_BinOp(a, FloorDiv, b, EXTRA) }\n"
"    | a=term '%' b=factor { _Py_BinOp(a, Mod, b, EXTRA) }\n"
"    | a=term '@' b=factor { CHECK_VERSION(5, \"The '@' operator is\", "
"_Py_BinOp(a, MatMult, b, EXTRA)) }\n"
"    | factor\n"
"factor[expr_ty] (memo):\n"
"    | '+' a=factor { _Py_UnaryOp(UAdd, a, EXTRA) }\n"
"    | '-' a=factor { _Py_UnaryOp(USub, a, EXTRA) }\n"
"    | '~' a=factor { _Py_UnaryOp(Invert, a, EXTRA) }\n"
"    | power\n"
"power[expr_ty]:\n"
"    | a=await_primary '**' b=factor { _Py_BinOp(a, Pow, b, EXTRA) }\n"
"    | await_primary\n"
"await_primary[expr_ty] (memo):\n"
"    | AWAIT a=primary { CHECK_VERSION(5, \"Await expressions are\", "
"_Py_Await(a, EXTRA)) }\n"
"    | primary\n"
"primary[expr_ty]:\n"
"    | invalid_primary  # must be before 'primay genexp' because of "
"invalid_genexp\n"
"    | a=primary '.' b=NAME { _Py_Attribute(a, b->v.Name.id, Load, EXTRA) }\n"
"    | a=primary b=genexp { _Py_Call(a, CHECK(_PyPegen_singleton_seq(p, b)), "
"NULL, EXTRA) }\n"
"    | a=primary '(' b=[arguments] ')' {\n"
"        _Py_Call(a,\n"
"                 (b) ? ((expr_ty) b)->v.Call.args : NULL,\n"
"                 (b) ? ((expr_ty) b)->v.Call.keywords : NULL,\n"
"                 EXTRA) }\n"
"    | a=primary '[' b=slices ']' { _Py_Subscript(a, b, Load, EXTRA) }\n"
"    | atom\n"
"\n"
"slices[expr_ty]:\n"
"    | a=slice !',' { a }\n"
"    | a=','.slice+ [','] { _Py_Tuple(a, Load, EXTRA) }\n"
"slice[expr_ty]:\n"
"    | a=[expression] ':' b=[expression] c=[':' d=[expression] { d }] "
"{ _Py_Slice(a, b, c, EXTRA) }\n"
"    | a=expression { a }\n"
"atom[expr_ty]:\n"
"    | NAME\n"
"    | 'True' { _Py_Constant(Py_True, NULL, EXTRA) }\n"
"    | 'False' { _Py_Constant(Py_False, NULL, EXTRA) }\n"
"    | 'None' { _Py_Constant(Py_None, NULL, EXTRA) }\n"
"    | '__peg_parser__' { RAISE_SYNTAX_ERROR(\"You found it!\") }\n"
"    | &STRING strings\n"
"    | NUMBER\n"
"    | &'(' (tuple | group | genexp)\n"
"    | &'[' (list | listcomp)\n"
"    | &'{' (dict | set | dictcomp | setcomp)\n"
"    | '...' { _Py_Constant(Py_Ellipsis, NULL, EXTRA) }\n"
"\n"
"strings[expr_ty] (memo): a=STRING+ { _PyPegen_concatenate_strings(p, a) }\n"
"list[expr_ty]:\n"
"    | '[' a=[star_named_expressions] ']' { _Py_List(a, Load, EXTRA) }\n"
"listcomp[expr_ty]:\n"
"    | '[' a=named_expression ~ b=for_if_clauses ']' { _Py_ListComp(a, b, "
"EXTRA) }\n"
"    | invalid_comprehension\n"
"tuple[expr_ty]:\n"
"    | '(' a=[y=star_named_expression ',' z=[star_named_expressions] "
"{ _PyPegen_seq_insert_in_front(p, y, z) } ] ')' {\n"
"        _Py_Tuple(a, Load, EXTRA) }\n"
"group[expr_ty]:\n"
"    | '(' a=(yield_expr | named_expression) ')' { a }\n"
"    | invalid_group\n"
"genexp[expr_ty]:\n"
"    | '(' a=named_expression ~ b=for_if_clauses ')' { _Py_GeneratorExp(a, b, "
"EXTRA) }\n"
"    | invalid_comprehension\n"
"set[expr_ty]: '{' a=star_named_expressions '}' { _Py_Set(a, EXTRA) }\n"
"setcomp[expr_ty]:\n"
"    | '{' a=named_expression ~ b=for_if_clauses '}' { _Py_SetComp(a, b, "
"EXTRA) }\n"
"    | invalid_comprehension\n"
"dict[expr_ty]:\n"
"    | '{' a=[double_starred_kvpairs] '}' {\n"
"        _Py_Dict(CHECK(_PyPegen_get_keys(p, a)), "
"CHECK(_PyPegen_get_values(p, a)), EXTRA) }\n"
"dictcomp[expr_ty]:\n"
"    | '{' a=kvpair b=for_if_clauses '}' { _Py_DictComp(a->key, a->value, b, "
"EXTRA) }\n"
"    | invalid_dict_comprehension\n"
"double_starred_kvpairs[asdl_seq*]: a=','.double_starred_kvpair+ [','] { a }\n"
"double_starred_kvpair[KeyValuePair*]:\n"
"    | '**' a=bitwise_or { _PyPegen_key_value_pair(p, NULL, a) }\n"
"    | kvpair\n"
"kvpair[KeyValuePair*]: a=expression ':' b=expression "
"{ _PyPegen_key_value_pair(p, a, b) }\n"
"for_if_clauses[asdl_seq*]:\n"
"    | for_if_clause+\n"
"for_if_clause[comprehension_ty]:\n"
"    | ASYNC 'for' a=star_targets 'in' ~ b=disjunction c=('if' z=disjunction "
"{ z })* {\n"
"        CHECK_VERSION(6, \"Async comprehensions are\", _Py_comprehension(a, "
"b, c, 1, p->arena)) }\n"
"    | 'for' a=star_targets 'in' ~ b=disjunction c=('if' z=disjunction "
"{ z })* {\n"
"        _Py_comprehension(a, b, c, 0, p->arena) }\n"
"    | invalid_for_target\n"
"\n"
"yield_expr[expr_ty]:\n"
"    | 'yield' 'from' a=expression { _Py_YieldFrom(a, EXTRA) }\n"
"    | 'yield' a=[star_expressions] { _Py_Yield(a, EXTRA) }\n"
"\n"
"arguments[expr_ty] (memo):\n"
"    | a=args [','] &')' { a }\n"
"    | invalid_arguments\n"
"args[expr_ty]:\n"
"    | a=','.(starred_expression | named_expression !'=')+ b=[',' k=kwargs "
"{k}] { _PyPegen_collect_call_seqs(p, a, b, EXTRA) }\n"
"    | a=kwargs { _Py_Call(_PyPegen_dummy_name(p),\n"
"                          CHECK_NULL_ALLOWED(_PyPegen_seq_extract_starred_exprs(p, "
"a)),\n"
"                          CHECK_NULL_ALLOWED(_PyPegen_seq_delete_starred_exprs(p, "
"a)),\n"
"                          EXTRA) }\n"
"kwargs[asdl_seq*]:\n"
"    | a=','.kwarg_or_starred+ ',' b=','.kwarg_or_double_starred+ "
"{ _PyPegen_join_sequences(p, a, b) }\n"
"    | ','.kwarg_or_starred+\n"
"    | ','.kwarg_or_double_starred+\n"
"starred_expression[expr_ty]:\n"
"    | '*' a=expression { _Py_Starred(a, Load, EXTRA) }\n"
"kwarg_or_starred[KeywordOrStarred*]:\n"
"    | a=NAME '=' b=expression {\n"
"        _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(a->v.Name.id, b, "
"EXTRA)), 1) }\n"
"    | a=starred_expression { _PyPegen_keyword_or_starred(p, a, 0) }\n"
"    | invalid_kwarg\n"
"kwarg_or_double_starred[KeywordOrStarred*]:\n"
"    | a=NAME '=' b=expression {\n"
"        _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(a->v.Name.id, b, "
"EXTRA)), 1) }\n"
"    | '**' a=expression { _PyPegen_keyword_or_starred(p, "
"CHECK(_Py_keyword(NULL, a, EXTRA)), 1) }\n"
"    | invalid_kwarg\n"
"\n"
"# NOTE: star_targets may contain *bitwise_or, targets may not.\n"
"star_targets[expr_ty]:\n"
"    | a=star_target !',' { a }\n"
"    | a=star_target b=(',' c=star_target { c })* [','] {\n"
"        _Py_Tuple(CHECK(_PyPegen_seq_insert_in_front(p, a, b)), Store, "
"EXTRA) }\n"
"star_targets_list_seq[asdl_seq*]: a=','.star_target+ [','] { a }\n"
"star_targets_tuple_seq[asdl_seq*]:\n"
"    | a=star_target b=(',' c=star_target { c })+ [','] "
"{ _PyPegen_seq_insert_in_front(p, a, b) }\n"
"    | a=star_target ',' { _PyPegen_singleton_seq(p, a) }\n"
"star_target[expr_ty] (memo):\n"
"    | '*' a=(!'*' star_target) {\n"
"        _Py_Starred(CHECK(_PyPegen_set_expr_context(p, a, Store)), Store, "
"EXTRA) }\n"
"    | target_with_star_atom\n"
"target_with_star_atom[expr_ty] (memo):\n"
"    | a=t_primary '.' b=NAME !t_lookahead { _Py_Attribute(a, b->v.Name.id, "
"Store, EXTRA) }\n"
"    | a=t_primary '[' b=slices ']' !t_lookahead { _Py_Subscript(a, b, Store, "
"EXTRA) }\n"
"    | star_atom\n"
"star_atom[expr_ty]:\n"
"    | a=NAME { _PyPegen_set_expr_context(p, a, Store) }\n"
"    | '(' a=target_with_star_atom ')' { _PyPegen_set_expr_context(p, a, "
"Store) }\n"
"    | '(' a=[star_targets_tuple_seq] ')' { _Py_Tuple(a, Store, EXTRA) }\n"
"    | '[' a=[star_targets_list_seq] ']' { _Py_List(a, Store, EXTRA) }\n"
"\n"
"single_target[expr_ty]:\n"
"    | single_subscript_attribute_target\n"
"    | a=NAME { _PyPegen_set_expr_context(p, a, Store) }\n"
"    | '(' a=single_target ')' { a }\n"
"single_subscript_attribute_target[expr_ty]:\n"
"    | a=t_primary '.' b=NAME !t_lookahead { _Py_Attribute(a, b->v.Name.id, "
"Store, EXTRA) }\n"
"    | a=t_primary '[' b=slices ']' !t_lookahead { _Py_Subscript(a, b, Store, "
"EXTRA) }\n"
"\n"
"del_targets[asdl_seq*]: a=','.del_target+ [','] { a }\n"
"del_target[expr_ty] (memo):\n"
"    | a=t_primary '.' b=NAME !t_lookahead { _Py_Attribute(a, b->v.Name.id, "
"Del, EXTRA) }\n"
"    | a=t_primary '[' b=slices ']' !t_lookahead { _Py_Subscript(a, b, Del, "
"EXTRA) }\n"
"    | del_t_atom\n"
"del_t_atom[expr_ty]:\n"
"    | a=NAME { _PyPegen_set_expr_context(p, a, Del) }\n"
"    | '(' a=del_target ')' { _PyPegen_set_expr_context(p, a, Del) }\n"
"    | '(' a=[del_targets] ')' { _Py_Tuple(a, Del, EXTRA) }\n"
"    | '[' a=[del_targets] ']' { _Py_List(a, Del, EXTRA) }\n"
"\n"
"t_primary[expr_ty]:\n"
"    | a=t_primary '.' b=NAME &t_lookahead { _Py_Attribute(a, b->v.Name.id, "
"Load, EXTRA) }\n"
"    | a=t_primary '[' b=slices ']' &t_lookahead { _Py_Subscript(a, b, Load, "
"EXTRA) }\n"
"    | a=t_primary b=genexp &t_lookahead { _Py_Call(a, "
"CHECK(_PyPegen_singleton_seq(p, b)), NULL, EXTRA) }\n"
"    | a=t_primary '(' b=[arguments] ')' &t_lookahead {\n"
"        _Py_Call(a,\n"
"                 (b) ? ((expr_ty) b)->v.Call.args : NULL,\n"
"                 (b) ? ((expr_ty) b)->v.Call.keywords : NULL,\n"
"                 EXTRA) }\n"
"    | a=atom &t_lookahead { a }\n"
"t_lookahead: '(' | '[' | '.'\n"
"\n"
"# From here on, there are rules for invalid syntax with specialised error "
"messages\n"
"invalid_arguments:\n"
"    | args ',' '*' { RAISE_SYNTAX_ERROR(\"iterable argument unpacking "
"follows keyword argument unpacking\") }\n"
"    | a=expression for_if_clauses ',' [args | expression for_if_clauses] {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"Generator expression must be "
"parenthesized\") }\n"
"    | a=args for_if_clauses { _PyPegen_nonparen_genexp_in_call(p, a) }\n"
"    | args ',' a=expression for_if_clauses {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"Generator expression must be "
"parenthesized\") }\n"
"    | a=args ',' args { _PyPegen_arguments_parsing_error(p, a) }\n"
"invalid_kwarg:\n"
"    | !(NAME '=') a=expression b='=' {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(\n"
"            a, \"expression cannot contain assignment, perhaps you meant \\"
"\"==\\\"?\") }\n"
"invalid_named_expression:\n"
"    | a=expression ':=' expression {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(\n"
"            a, \"cannot use assignment expressions with %s\", "
"_PyPegen_get_expr_name(a)) }\n"
"invalid_assignment:\n"
"    | a=invalid_ann_assign_target ':' expression {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(\n"
"            a,\n"
"            \"only single target (not %s) can be annotated\",\n"
"            _PyPegen_get_expr_name(a)\n"
"        )}\n"
"    | a=star_named_expression ',' star_named_expressions* ':' expression {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"only single target (not "
"tuple) can be annotated\") }\n"
"    | a=expression ':' expression {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"illegal target for "
"annotation\") }\n"
"    | (star_targets '=')* a=star_expressions '=' {\n"
"        RAISE_SYNTAX_ERROR_INVALID_TARGET(STAR_TARGETS, a) }\n"
"    | (star_targets '=')* a=yield_expr "
"'=' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"assignment to yield expression "
"not possible\") }\n"
"    | a=star_expressions augassign (yield_expr | star_expressions) {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION( \n"
"            a,\n"
"            \"'%s' is an illegal expression for augmented assignment\",\n"
"            _PyPegen_get_expr_name(a)\n"
"        )}\n"
"invalid_ann_assign_target[expr_ty]:\n"
"    | list\n"
"    | tuple\n"
"    | '(' a=invalid_ann_assign_target ')' { a }\n"
"invalid_del_stmt:\n"
"    | 'del' a=star_expressions {\n"
"        RAISE_SYNTAX_ERROR_INVALID_TARGET(DEL_TARGETS, a) }\n"
"invalid_block:\n"
"    | NEWLINE !INDENT { RAISE_INDENTATION_ERROR(\"expected an indented "
"block\") }\n"
"invalid_primary:\n"
"    | primary a='{' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"invalid "
"syntax\") }\n"
"invalid_comprehension:\n"
"    | ('[' | '(' | '{') a=starred_expression for_if_clauses {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"iterable unpacking cannot be "
"used in comprehension\") }\n"
"invalid_dict_comprehension:\n"
"    | '{' a='**' bitwise_or for_if_clauses '}' {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"dict unpacking cannot be used "
"in dict comprehension\") }\n"
"invalid_parameters:\n"
"    | param_no_default* (slash_with_default | param_with_default+) "
"param_no_default {\n"
"        RAISE_SYNTAX_ERROR(\"non-default argument follows default "
"argument\") }\n"
"invalid_lambda_parameters:\n"
"    | lambda_param_no_default* (lambda_slash_with_default | "
"lambda_param_with_default+) lambda_param_no_default {\n"
"        RAISE_SYNTAX_ERROR(\"non-default argument follows default "
"argument\") }\n"
"invalid_star_etc:\n"
"    | '*' (')' | ',' (')' | '**')) { RAISE_SYNTAX_ERROR(\"named arguments "
"must follow bare *\") }\n"
"    | '*' ',' TYPE_COMMENT { RAISE_SYNTAX_ERROR(\"bare * has associated type "
"comment\") }\n"
"invalid_lambda_star_etc:\n"
"    | '*' (':' | ',' (':' | '**')) { RAISE_SYNTAX_ERROR(\"named arguments "
"must follow bare *\") }\n"
"invalid_double_type_comments:\n"
"    | TYPE_COMMENT NEWLINE TYPE_COMMENT NEWLINE INDENT {\n"
"        RAISE_SYNTAX_ERROR(\"Cannot have two type comments on def\") }\n"
"invalid_with_item:\n"
"    | expression 'as' a=expression {\n"
"        RAISE_SYNTAX_ERROR_INVALID_TARGET(STAR_TARGETS, a) }\n"
"\n"
"invalid_for_target:\n"
"    | ASYNC? 'for' a=star_expressions {\n"
"        RAISE_SYNTAX_ERROR_INVALID_TARGET(FOR_TARGETS, a) }\n"
"\n"
"invalid_group:\n"
"    | '(' a=starred_expression ')' {\n"
"        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, \"can't use starred expression "
"here\") }\n"
"invalid_import_from_targets:\n"
"    | import_from_as_names ',' NEWLINE {\n"
"        RAISE_SYNTAX_ERROR(\"trailing comma not allowed without surrounding "
"parentheses\") }\n"
msgstr ""
